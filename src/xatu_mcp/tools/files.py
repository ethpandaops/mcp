"""File management tools for output files."""

import re
from typing import Any

from mcp.types import TextContent, Tool
import structlog

from xatu_mcp.config import Config

logger = structlog.get_logger()

# Valid filename pattern - alphanumeric, underscores, hyphens, dots, no path separators
_SAFE_FILENAME_PATTERN = re.compile(r'^[a-zA-Z0-9_\-][a-zA-Z0-9_\-\.]*$')


def _validate_filename(filename: str) -> str:
    """Validate a filename to prevent path traversal attacks.

    Args:
        filename: The filename to validate.

    Returns:
        The validated filename.

    Raises:
        ValueError: If the filename is invalid or potentially malicious.
    """
    if not filename:
        raise ValueError("filename cannot be empty")

    # Check for path traversal attempts
    if '/' in filename or '\\' in filename:
        raise ValueError("filename cannot contain path separators")
    if filename.startswith('.'):
        raise ValueError("filename cannot start with '.'")
    if '..' in filename:
        raise ValueError("filename cannot contain '..'")

    # Check against allowed pattern
    if not _SAFE_FILENAME_PATTERN.match(filename):
        raise ValueError(
            "filename must contain only alphanumeric characters, underscores, hyphens, and dots"
        )

    # Length check
    if len(filename) > 255:
        raise ValueError("filename too long (max 255 characters)")

    return filename


def build_file_tools() -> list[Tool]:
    """Build the file management tool definitions.

    Returns:
        List of Tool definitions for file management.
    """
    return [
        Tool(
            name="get_output_file",
            description="""Get a URL for an output file generated by execute_python.

After code execution, output files are stored temporarily and can be
retrieved via this tool. The server uploads files to S3-compatible
storage and returns a public URL.

Files are available for a limited time after execution.""",
            inputSchema={
                "type": "object",
                "properties": {
                    "filename": {
                        "type": "string",
                        "description": "Name of the file in /output/ directory",
                    },
                    "execution_id": {
                        "type": "string",
                        "description": "Execution ID (optional, uses most recent if not specified)",
                    },
                },
                "required": ["filename"],
            },
        ),
        Tool(
            name="list_output_files",
            description="""List all output files from the most recent execution.

Returns the filenames of all files that were written to /output/
during code execution.""",
            inputSchema={
                "type": "object",
                "properties": {
                    "execution_id": {
                        "type": "string",
                        "description": "Execution ID (optional, uses most recent if not specified)",
                    },
                },
            },
        ),
    ]


async def handle_get_output_file(
    arguments: dict[str, Any],
    config: Config,
) -> list[TextContent]:
    """Handle the get_output_file tool call.

    Args:
        arguments: Tool arguments.
        config: Server configuration.

    Returns:
        Text content with file URL or error message.

    Raises:
        ValueError: If filename is missing or invalid.
    """
    filename = arguments.get("filename")
    if not filename:
        raise ValueError("filename is required")

    # Validate filename to prevent path traversal
    safe_filename = _validate_filename(filename)

    execution_id = arguments.get("execution_id")
    if execution_id:
        # Also validate execution_id format (should be alphanumeric)
        if not re.match(r'^[a-zA-Z0-9_\-]+$', execution_id):
            raise ValueError("execution_id must be alphanumeric")

    logger.info(
        "Getting output file",
        filename=safe_filename,
        execution_id=execution_id,
    )

    # In a real implementation, this would:
    # 1. Look up the file in the output directory for the execution
    # 2. Upload it to S3 if not already uploaded
    # 3. Return a presigned URL

    # For now, return a placeholder
    if config.storage:
        base_url = config.storage.public_url_prefix or f"{config.storage.endpoint}/{config.storage.bucket}"
        file_key = f"{execution_id or 'latest'}/{safe_filename}"
        url = f"{base_url}/{file_key}"

        return [
            TextContent(
                type="text",
                text=f"URL: {url}\n\nNote: File upload to S3 not yet implemented. "
                "In production, this would return a presigned URL to the uploaded file.",
            )
        ]
    else:
        return [
            TextContent(
                type="text",
                text="Error: Storage not configured. Add storage configuration to enable file retrieval.",
            )
        ]


async def handle_list_output_files(
    arguments: dict[str, Any],
    config: Config,
) -> list[TextContent]:
    """Handle the list_output_files tool call.

    Args:
        arguments: Tool arguments.
        config: Server configuration.

    Returns:
        Text content with list of files or error message.
    """
    execution_id = arguments.get("execution_id")

    if execution_id:
        # Validate execution_id format
        if not re.match(r'^[a-zA-Z0-9_\-]+$', execution_id):
            raise ValueError("execution_id must be alphanumeric")

    logger.info(
        "Listing output files",
        execution_id=execution_id,
    )

    # In a real implementation, this would list files from the execution's output directory
    # For now, return a placeholder

    return [
        TextContent(
            type="text",
            text="No output files found.\n\nNote: Output file tracking not yet fully implemented. "
            "Use execute_python to generate output files.",
        )
    ]
